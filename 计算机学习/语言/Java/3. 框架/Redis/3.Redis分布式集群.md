# Redis分布式集群
#分布式 #redis #redis集群

## 分布式集群的演进——以redis为例
### 1.redis可用性产生问题：
1. 单点故障
  -> 主从主备：一变多，互为镜像 HA  **需要数据同步！**
2. 并发压力
  -> 分片集群 代理集群  一变多    **不需要数据同步！**
  
> 两个方案通常会整合使用

引入了HA集群(提高可用性)，自然涉及到数据一致性：
### 2.redis数据同步

主从复制(数据一致性的三种要求)：
- 强一致性：保存数据时，所有 redis节点都保存成功后，再返回保存成功
   > 强一致性会破坏可用性 (要等待异常节点恢复正常并写入数据) 见[[CAP]]
- 弱一致性(默认)：保存数据时，自己保存成功即成功，异步进行同步操作，不保证成功
   > 可用性(A)强，一致性(C)低
   > *缓存场景中无所谓，数据重要时不行(分布式锁，存重要数据)*
- 最终一致性(redis未实现)：保存数据时，向一个**可靠**节点同步数据成功后返回成功，其他节点都依赖这个可靠节点来达到最终数据的一致。
   > HDFS 有这个功能
   > 如何实现这个**可靠节点**？ 见 [[]]

## redis分片集群的组建 [[分片集群]] 
* 分片之后仍然需要 HA 需要主备组高可用！
1. redis客户端自己实现分片算法 弊端见 [[分片集群]]
2. 使用redis代理组件 弊端见 [[分片集群]]
   -  [predixy](https://github.com/joyieldInc/predixy)
   -   [twemproxy](https://github.com/twitter/twemproxy)
   -   [codis](https://github.com/CodisLabs/codis/)
   -   [redis-cerberus](https://github.com/projecteru/redis-cerberus)
3.  使用redis的 集群功能
   
   > 分片算法：
   > 预制槽位: 16384 算法对key的hash取模的时候取得是16384的模，之后再根据映射关系找到节点。 --> 方便rehash