# 高并发，高性能，高可用
#实战

集群！
分两种：
HA（Highly Available） 高可用

## 方法论 AKF:
 > x 轴可靠性 数据是全量的 ->HA     | 服务横向扩展 数据一致 多份
 > y 轴分治 按业务划分                      |按业务分计算与数据
 > z 轴                                                |存每个业务中的n分之1的数据
 >  - 计算： 分治后的的服务做集群 基于反向代理的负载均衡  = x轴？
 >  - 数据： 分片（sharding）对于 redis mysql 分库发表 **业务内的数据拆分**
x 轴：全量 镜像
y轴：业务，功能
z轴：优先级，分片

对于计算节点 实现 y与z即可高可用 ？
对于数据节点不行，数据节点要有主备。
z轴：分而治之后如何找数据？ 路由 映射 索引
  1. 中间件 
  2. 预分区 虚拟槽

### HA（Highly Available） 高可用的特点：
 -  LVS四层  tcp
 -  node 是一样的， 存储的是全量，session和其他数据一致性问题
   >  这时解决数据一致性问题可以使用：
   >  1. 同步机制(相互同步)， 但是同步很难实现 --> paxos
   >  2. 数据集中也可以处理 -> 如用redis存
   >  简历集群让单笔请求性能变低，但是连接数会提高 -> 高并发 (突破单机资源约束 CPU 硬盘io )



进一步发展 业务功能模块相对较多 
-> 倾斜 每个不同模块耗时不同 可能会将耗时操作负载到同一台机器,导致排在大负载模块后的其他模块耗时无法控制。
 ->分治 - 服务拆分 使用nginx 反向代理 分治后的服务模块（七层 http）
-> 根据压力的不同分别调整服务模块的数量，使用nginx负载均衡。
->单台官方nginx连接5000左右 单台不够？ nginx 扩展 增加lvs 做负载均衡
-> 还不够。数据中心、静态资源CDN

就有了
lvs 流程层 
nginx 接入层
服务 业务层


在服务分治后，还是倾斜 （分配问题？）
